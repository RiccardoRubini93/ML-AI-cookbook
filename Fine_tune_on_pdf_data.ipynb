{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwZ8v+VMLiIxTFdLrXIo8C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7db5077b9b374aa7a7588d797c0e0e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_588c9f27bee84732933935f5fb9c0a97",
              "IPY_MODEL_e0095a19946548309ae38240c853e6ee",
              "IPY_MODEL_f93249e224a041319f43fe94acaa0035"
            ],
            "layout": "IPY_MODEL_f8df8ce3536b401aa7cbc79bfaac9bd2"
          }
        },
        "588c9f27bee84732933935f5fb9c0a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11acd3665a504b8b87e609029a04461c",
            "placeholder": "​",
            "style": "IPY_MODEL_0f74e36bb41945fd80508d542d8e7191",
            "value": "config.json: 100%"
          }
        },
        "e0095a19946548309ae38240c853e6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e91d3f28904256b8a89deaea4a29f4",
            "max": 627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e7df560f2294d3894c59c3619f73237",
            "value": 627
          }
        },
        "f93249e224a041319f43fe94acaa0035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee4fe390025544fe8e98a06e48e397d2",
            "placeholder": "​",
            "style": "IPY_MODEL_7efb9454bafe4e96940dd0c517e5bc29",
            "value": " 627/627 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "f8df8ce3536b401aa7cbc79bfaac9bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11acd3665a504b8b87e609029a04461c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f74e36bb41945fd80508d542d8e7191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1e91d3f28904256b8a89deaea4a29f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7df560f2294d3894c59c3619f73237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee4fe390025544fe8e98a06e48e397d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efb9454bafe4e96940dd0c517e5bc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "382c7ba3816748cea52577961a8f3fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd73e24b6ab24a0cb809dc36d5053676",
              "IPY_MODEL_2253c886682e4d7796a61bd33703a816",
              "IPY_MODEL_b387510508f8454ba2b6fef483fa9d0a"
            ],
            "layout": "IPY_MODEL_db82b3c7b5c742629877059318700cf2"
          }
        },
        "fd73e24b6ab24a0cb809dc36d5053676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_035a7b558fc643cab8565dfa762b8d6a",
            "placeholder": "​",
            "style": "IPY_MODEL_1754e892159f4a73b334f328dcc12d41",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "2253c886682e4d7796a61bd33703a816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1f58789d1ac485da316c13a863404f1",
            "max": 242013444,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be9225e7908b467b88d8c9102afb15d4",
            "value": 242013444
          }
        },
        "b387510508f8454ba2b6fef483fa9d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59a6fd1fa214327aa33aa24ead5668d",
            "placeholder": "​",
            "style": "IPY_MODEL_5094635099d24628b577ff16d2f98930",
            "value": " 242M/242M [00:01&lt;00:00, 231MB/s]"
          }
        },
        "db82b3c7b5c742629877059318700cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035a7b558fc643cab8565dfa762b8d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1754e892159f4a73b334f328dcc12d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1f58789d1ac485da316c13a863404f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9225e7908b467b88d8c9102afb15d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f59a6fd1fa214327aa33aa24ead5668d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5094635099d24628b577ff16d2f98930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3ce3b0149b3409e8b2666aa49a026aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52f3e41d9b86499b935d06fe793e7f9d",
              "IPY_MODEL_f71bbcabd7b845c18c78346addc4f46c",
              "IPY_MODEL_e19e5d6d95bb4bd9895192fb2cf267c3"
            ],
            "layout": "IPY_MODEL_1564cbbc2be14c4ca4805c5208d6c27a"
          }
        },
        "52f3e41d9b86499b935d06fe793e7f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d6ecf260943490885d284a9fdd123d3",
            "placeholder": "​",
            "style": "IPY_MODEL_25d27eb98e5a4fe69e142ea2c2ff72f6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f71bbcabd7b845c18c78346addc4f46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60710ba64e914f67b43bd74a7bef777b",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6189cd1e179a4852b45411733095caee",
            "value": 90
          }
        },
        "e19e5d6d95bb4bd9895192fb2cf267c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59f2d0e19e24aa09ae293cdf41f81f8",
            "placeholder": "​",
            "style": "IPY_MODEL_ddae068f921a47d580d9c3a88c858baa",
            "value": " 90.0/90.0 [00:00&lt;00:00, 10.2kB/s]"
          }
        },
        "1564cbbc2be14c4ca4805c5208d6c27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6ecf260943490885d284a9fdd123d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d27eb98e5a4fe69e142ea2c2ff72f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60710ba64e914f67b43bd74a7bef777b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6189cd1e179a4852b45411733095caee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a59f2d0e19e24aa09ae293cdf41f81f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddae068f921a47d580d9c3a88c858baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b27d19f7bcc84b0d955b72151e3e52b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bd4f8c5c95c4d2ca13f9d1b23331c0a",
              "IPY_MODEL_1dd91e0307b645448d424ad21584a225",
              "IPY_MODEL_d793e89f030c4ee281408451d71e3c7e"
            ],
            "layout": "IPY_MODEL_7ad087d9f2b847fca96a285f4c6cf334"
          }
        },
        "7bd4f8c5c95c4d2ca13f9d1b23331c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c713c7424f4749089d96e526e45343ed",
            "placeholder": "​",
            "style": "IPY_MODEL_0db4c86a169348ee90c3b8283519cd77",
            "value": "model.safetensors: 100%"
          }
        },
        "1dd91e0307b645448d424ad21584a225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c072f31c3041978186891bbcb760d7",
            "max": 241989808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d644873393b40cb865c52bb47d2bb8b",
            "value": 241989808
          }
        },
        "d793e89f030c4ee281408451d71e3c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d99d7dd14047058df91133c00ac0bb",
            "placeholder": "​",
            "style": "IPY_MODEL_faf8242e0269457f89f71990e527c463",
            "value": " 242M/242M [00:01&lt;00:00, 163MB/s]"
          }
        },
        "7ad087d9f2b847fca96a285f4c6cf334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c713c7424f4749089d96e526e45343ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db4c86a169348ee90c3b8283519cd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c072f31c3041978186891bbcb760d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d644873393b40cb865c52bb47d2bb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9d99d7dd14047058df91133c00ac0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf8242e0269457f89f71990e527c463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87ed5880ccb643718b82a044576e972f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5cec5b88d4e4581bb1e42aac298e343",
              "IPY_MODEL_c70a8cd6e7bc4e18b16c55ea5ebb4ccd",
              "IPY_MODEL_d2461104939e4128804ee246d722b6d1"
            ],
            "layout": "IPY_MODEL_73f57767db144ed6a51c45c5c7e4e523"
          }
        },
        "d5cec5b88d4e4581bb1e42aac298e343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d3ce69bb9c4a9f998813b67803cf3f",
            "placeholder": "​",
            "style": "IPY_MODEL_c1a2b1f76c464f219a3907323ef64b4e",
            "value": "spiece.model: 100%"
          }
        },
        "c70a8cd6e7bc4e18b16c55ea5ebb4ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d475d51a69134b559688bc3f511bd161",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5292f440ebc4443bccbc7a885a3fcb8",
            "value": 791656
          }
        },
        "d2461104939e4128804ee246d722b6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf371e4f216141c28bf76ff677bdfb8d",
            "placeholder": "​",
            "style": "IPY_MODEL_d3ef248a7dc249ffbe14dc324b186307",
            "value": " 792k/792k [00:00&lt;00:00, 16.9MB/s]"
          }
        },
        "73f57767db144ed6a51c45c5c7e4e523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d3ce69bb9c4a9f998813b67803cf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a2b1f76c464f219a3907323ef64b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d475d51a69134b559688bc3f511bd161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5292f440ebc4443bccbc7a885a3fcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf371e4f216141c28bf76ff677bdfb8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ef248a7dc249ffbe14dc324b186307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787a2cfc3134492ba17c9d61aa1cb1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af75984bb2e64253813ff0c64469fe3b",
              "IPY_MODEL_76e339e965c1492aac7f0dec70cf6f7e",
              "IPY_MODEL_b164d2843743454f8d4a79e5e8d8cb01"
            ],
            "layout": "IPY_MODEL_7c51e3ed584448b3acbfe4ce9132ab1e"
          }
        },
        "af75984bb2e64253813ff0c64469fe3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ecbe002b274ea18715549555b686f5",
            "placeholder": "​",
            "style": "IPY_MODEL_136a669aaeee4778b68d094d739b9e09",
            "value": "added_tokens.json: 100%"
          }
        },
        "76e339e965c1492aac7f0dec70cf6f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b139cda799241cbb526483bea782fd8",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72964aee5f38412493f00d9583b3372a",
            "value": 31
          }
        },
        "b164d2843743454f8d4a79e5e8d8cb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cbd6d3af738467492fae31996322834",
            "placeholder": "​",
            "style": "IPY_MODEL_4dfe6bc6e48e474ebe9013334d921e7a",
            "value": " 31.0/31.0 [00:00&lt;00:00, 2.35kB/s]"
          }
        },
        "7c51e3ed584448b3acbfe4ce9132ab1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ecbe002b274ea18715549555b686f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136a669aaeee4778b68d094d739b9e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b139cda799241cbb526483bea782fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72964aee5f38412493f00d9583b3372a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cbd6d3af738467492fae31996322834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfe6bc6e48e474ebe9013334d921e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2358818c70242c3b3a189b84e3bde36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d3e0a2e17b244a2925376e1f3bf2cea",
              "IPY_MODEL_f1405c39e47b4374871be1dd6ae7200e",
              "IPY_MODEL_1d5a6fc645cf43c2a6d51eade6131081"
            ],
            "layout": "IPY_MODEL_d114b140dfbd4d1f90776ae26fe9d957"
          }
        },
        "8d3e0a2e17b244a2925376e1f3bf2cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11df36c816294d2e99524fc9b355b8dd",
            "placeholder": "​",
            "style": "IPY_MODEL_f7c86542c9f14cdb90456153a84703b2",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f1405c39e47b4374871be1dd6ae7200e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3003a1281c9437798886a178e5eb4fe",
            "max": 65,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5ab99fd723449b08e49ea4672c75849",
            "value": 65
          }
        },
        "1d5a6fc645cf43c2a6d51eade6131081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fdefd3b8aca4fd2bf9ce0f965a94610",
            "placeholder": "​",
            "style": "IPY_MODEL_a0dbea29f2ca45bdbe96c6bccbc16a7b",
            "value": " 65.0/65.0 [00:00&lt;00:00, 1.55kB/s]"
          }
        },
        "d114b140dfbd4d1f90776ae26fe9d957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11df36c816294d2e99524fc9b355b8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c86542c9f14cdb90456153a84703b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3003a1281c9437798886a178e5eb4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ab99fd723449b08e49ea4672c75849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fdefd3b8aca4fd2bf9ce0f965a94610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0dbea29f2ca45bdbe96c6bccbc16a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiccardoRubini93/ML-AI-cookbook/blob/main/Fine_tune_on_pdf_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "id": "YZyE7284XE7u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLa9eD3vZX9J",
        "outputId": "b0a8f753-e3c2-47a6-bfb5-e3898a7cd753"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "g4Gm8u2iXl3S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_references(text):\n",
        "    # Remove text after \"REFERENCES\"\n",
        "    reference_start = text.find(\"REFERENCES\")\n",
        "    if reference_start != -1:\n",
        "        text = text[:reference_start]\n",
        "\n",
        "    return text\n",
        "\n",
        "def remove_links(text):\n",
        "    pattern = r\"\\[\\d+\\]|\\(http[s]?://\\S+\\)|www\\.\\S+|[^a-zA-Z0-9\\s]\"\n",
        "    return re.sub(pattern, \"\", text)\n",
        "\n",
        "def remove_special_chars(text):\n",
        "    pattern = r\"[^\\w\\s.]\"\n",
        "    return re.sub(pattern, \"\", text)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = remove_references(text)\n",
        "    text = remove_links(text)\n",
        "    text = text.lower()\n",
        "    text = remove_special_chars(text)\n",
        "\n",
        "    text = re.sub(r'\\[\\d*\\]', '', text)  # Remove square brackets containing numbers\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)   # Remove other text between square brackets\n",
        "\n",
        "    # Remove occurrences of \"fig\"\n",
        "    text = re.sub(r'\\bfig.\\b', '', text)\n",
        "\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text)  # Remove numbers\n",
        "\n",
        "    # Remove single characters or numbers in a line\n",
        "    text = re.sub(r'\\b\\w\\b|\\b\\d\\b', '', text)\n",
        "\n",
        "    # Filter out lines with only a single character, number, or special character\n",
        "    lines = text.split('\\n')\n",
        "    lines = [line for line in lines if len(line.strip()) > 1]  # Filter out lines with length <= 1\n",
        "    text = '\\n'.join(lines)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "VRuhTRBMXvtR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PYgSoqGlahv7",
        "outputId": "76a429d2-8a64-4d35-af37-a45ea5b59b62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250416-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer_six-20250416-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20250416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the punkt tokenizer data\n",
        "nltk.download('punkt')\n",
        "print(\"NLTK punkt tokenizer successfully downloaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nww43tdsbk2l",
        "outputId": "529ce669-610f-46df-dd0b-017447ffc661"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK punkt tokenizer successfully downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y-roiExRWwjc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from pdfminer.high_level import extract_text\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess the extracted text from PDF files.\n",
        "    - Remove extra whitespace\n",
        "    - Remove non-ascii characters\n",
        "    - Convert to lowercase\n",
        "    \"\"\"\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove non-ascii characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from PDF using PyPDF2.\"\"\"\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def extract_sentences_from_folder(folder_path):\n",
        "    if not os.path.isdir(folder_path):\n",
        "        print(\"Folder path does not exist.\")\n",
        "        return []\n",
        "\n",
        "    sentences = []\n",
        "    for pdf_file in os.listdir(folder_path):\n",
        "        if pdf_file.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(folder_path, pdf_file)\n",
        "            try:\n",
        "                # Extract text from PDF\n",
        "                text = extract_text_from_pdf(pdf_path)\n",
        "                # Preprocess the extracted text\n",
        "                text = preprocess_text(text)\n",
        "\n",
        "                try:\n",
        "                    # Try to tokenize using NLTK\n",
        "                    pdf_sentences = sent_tokenize(text)\n",
        "                except LookupError:\n",
        "                    # Fallback: simple sentence splitting if NLTK fails\n",
        "                    print(f\"Warning: NLTK punkt tokenizer not available, using simple sentence splitting for {pdf_file}\")\n",
        "                    pdf_sentences = [s.strip() + '.' for s in text.split('.') if s.strip()]\n",
        "\n",
        "                sentences.extend(pdf_sentences)\n",
        "                print(f\"Processed: {pdf_file} - {len(pdf_sentences)} sentences\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {pdf_file}: {str(e)}\")\n",
        "\n",
        "    return sentences\n",
        "def write_to_txt(sentences, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as txt_file:\n",
        "        for sentence in sentences:\n",
        "            # Write each sentence in a new line\n",
        "            txt_file.write(sentence.strip() + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder containing PDF files\n",
        "pdf_folder = \"pdfs\"\n",
        "# Output file for preprocessed text\n",
        "output_file = \"text.txt\"\n",
        "\n",
        "# Extract sentences from PDF files\n",
        "sentences = extract_sentences_from_folder(pdf_folder)\n",
        "print(\"Total number of sentences extracted:\", len(sentences))\n",
        "\n",
        "# Write sentences to a text file\n",
        "write_to_txt(sentences, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65QuSq40amXd",
        "outputId": "40201871-b92a-4d95-f88e-e4609dec9455"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: NLTK punkt tokenizer not available, using simple sentence splitting for 2006.05736v2.pdf\n",
            "Processed: 2006.05736v2.pdf - 1166 sentences\n",
            "Total number of sentences extracted: 1166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_passages(input_file, output_file, words_per_passage=500):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    words = text.split()\n",
        "    passages = []\n",
        "    passage = \"\"\n",
        "    word_count = 0\n",
        "\n",
        "    # Iterate through words in the text\n",
        "    for word in words:\n",
        "        # Add word to current passage\n",
        "        passage += word + \" \"\n",
        "        word_count += 1\n",
        "\n",
        "        # Check if the word count exceeds the limit for a passage\n",
        "        if word_count >= words_per_passage:\n",
        "            passages.append(passage.strip())\n",
        "            passage = \"\"\n",
        "            word_count = 0\n",
        "\n",
        "    # Write passages to the output file\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for passage in passages:\n",
        "            f.write(passage + \"\\n\\n\")\n",
        "\n",
        "# Input and output file paths\n",
        "input_file = \"text.txt\"\n",
        "output_file = \"passages.txt\"\n",
        "\n",
        "# Call the function\n",
        "split_into_passages(input_file, output_file)"
      ],
      "metadata": {
        "id": "WPhNornlYRrn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def text_to_json(text_file, json_file, chunk_size=5):\n",
        "    \"\"\"\n",
        "    Convert a text file with sentences to a JSON file with passages.\n",
        "    Each passage is formed by combining chunk_size consecutive sentences.\n",
        "\n",
        "    Args:\n",
        "        text_file (str): Path to the input text file\n",
        "        json_file (str): Path to the output JSON file\n",
        "        chunk_size (int): Number of sentences to combine into one passage\n",
        "    \"\"\"\n",
        "    # Check if the text file exists\n",
        "    if not os.path.exists(text_file):\n",
        "        print(f\"Text file '{text_file}' does not exist.\")\n",
        "        return False\n",
        "\n",
        "    # Read the sentences from the text file\n",
        "    with open(text_file, 'r', encoding='utf-8') as f:\n",
        "        sentences = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    # Create passages by combining sentences\n",
        "    passages = []\n",
        "    for i in range(0, len(sentences), chunk_size):\n",
        "        chunk = sentences[i:i+chunk_size]\n",
        "        passage = \" \".join(chunk)\n",
        "        if passage:  # Only add non-empty passages\n",
        "            passages.append({\"answer\": passage})\n",
        "\n",
        "    # Write passages to JSON file\n",
        "    with open(json_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(passages, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Converted {len(sentences)} sentences into {len(passages)} passages.\")\n",
        "    print(f\"JSON file saved as '{json_file}'\")\n",
        "    return True\n",
        "\n",
        "text_file = \"passages.txt\"  # Your input text file\n",
        "json_file = \"output.json\"  # Output JSON file\n",
        "text_to_json(text_file, json_file, chunk_size=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tfdmKXUetqM",
        "outputId": "77e47074-63a1-40a7-8d2a-d4265d7a8e17"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 27 sentences into 6 passages.\n",
            "JSON file saved as 'output.json'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vPQG1rqrci31",
        "outputId": "52a6a15a-bb47-4c25-fc13-3c644ec917c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import json\n",
        "\n",
        "def generate_questions_with_transformers(json_file, output_file):\n",
        "    # Load the pre-trained question generation model and tokenizer\n",
        "    model_name = \"valhalla/t5-small-qg-hl\"\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    instructions = []\n",
        "    for item in data:\n",
        "        passage = item['answer']\n",
        "        # Tokenize the passage\n",
        "        inputs = tokenizer.encode(\"question: \" + passage, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "        # Generate questions using the model\n",
        "        questions = model.generate(inputs, max_length=64, num_beams=3, num_return_sequences=3, early_stopping=True)\n",
        "        for question in questions:\n",
        "            question_str = tokenizer.decode(question, skip_special_tokens=True)\n",
        "            instructions.append({\n",
        "                \"instruction\": f\"Based on the following passage: '{passage}', provide an accurate and relevant question.\",\n",
        "                \"input\": \"\",\n",
        "                \"output\": question_str\n",
        "            })\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(instructions, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "generate_questions_with_transformers('output.json', 'instructions.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "7db5077b9b374aa7a7588d797c0e0e71",
            "588c9f27bee84732933935f5fb9c0a97",
            "e0095a19946548309ae38240c853e6ee",
            "f93249e224a041319f43fe94acaa0035",
            "f8df8ce3536b401aa7cbc79bfaac9bd2",
            "11acd3665a504b8b87e609029a04461c",
            "0f74e36bb41945fd80508d542d8e7191",
            "a1e91d3f28904256b8a89deaea4a29f4",
            "0e7df560f2294d3894c59c3619f73237",
            "ee4fe390025544fe8e98a06e48e397d2",
            "7efb9454bafe4e96940dd0c517e5bc29",
            "382c7ba3816748cea52577961a8f3fb1",
            "fd73e24b6ab24a0cb809dc36d5053676",
            "2253c886682e4d7796a61bd33703a816",
            "b387510508f8454ba2b6fef483fa9d0a",
            "db82b3c7b5c742629877059318700cf2",
            "035a7b558fc643cab8565dfa762b8d6a",
            "1754e892159f4a73b334f328dcc12d41",
            "e1f58789d1ac485da316c13a863404f1",
            "be9225e7908b467b88d8c9102afb15d4",
            "f59a6fd1fa214327aa33aa24ead5668d",
            "5094635099d24628b577ff16d2f98930",
            "f3ce3b0149b3409e8b2666aa49a026aa",
            "52f3e41d9b86499b935d06fe793e7f9d",
            "f71bbcabd7b845c18c78346addc4f46c",
            "e19e5d6d95bb4bd9895192fb2cf267c3",
            "1564cbbc2be14c4ca4805c5208d6c27a",
            "0d6ecf260943490885d284a9fdd123d3",
            "25d27eb98e5a4fe69e142ea2c2ff72f6",
            "60710ba64e914f67b43bd74a7bef777b",
            "6189cd1e179a4852b45411733095caee",
            "a59f2d0e19e24aa09ae293cdf41f81f8",
            "ddae068f921a47d580d9c3a88c858baa",
            "b27d19f7bcc84b0d955b72151e3e52b7",
            "7bd4f8c5c95c4d2ca13f9d1b23331c0a",
            "1dd91e0307b645448d424ad21584a225",
            "d793e89f030c4ee281408451d71e3c7e",
            "7ad087d9f2b847fca96a285f4c6cf334",
            "c713c7424f4749089d96e526e45343ed",
            "0db4c86a169348ee90c3b8283519cd77",
            "66c072f31c3041978186891bbcb760d7",
            "2d644873393b40cb865c52bb47d2bb8b",
            "a9d99d7dd14047058df91133c00ac0bb",
            "faf8242e0269457f89f71990e527c463",
            "87ed5880ccb643718b82a044576e972f",
            "d5cec5b88d4e4581bb1e42aac298e343",
            "c70a8cd6e7bc4e18b16c55ea5ebb4ccd",
            "d2461104939e4128804ee246d722b6d1",
            "73f57767db144ed6a51c45c5c7e4e523",
            "96d3ce69bb9c4a9f998813b67803cf3f",
            "c1a2b1f76c464f219a3907323ef64b4e",
            "d475d51a69134b559688bc3f511bd161",
            "f5292f440ebc4443bccbc7a885a3fcb8",
            "bf371e4f216141c28bf76ff677bdfb8d",
            "d3ef248a7dc249ffbe14dc324b186307",
            "787a2cfc3134492ba17c9d61aa1cb1cd",
            "af75984bb2e64253813ff0c64469fe3b",
            "76e339e965c1492aac7f0dec70cf6f7e",
            "b164d2843743454f8d4a79e5e8d8cb01",
            "7c51e3ed584448b3acbfe4ce9132ab1e",
            "39ecbe002b274ea18715549555b686f5",
            "136a669aaeee4778b68d094d739b9e09",
            "7b139cda799241cbb526483bea782fd8",
            "72964aee5f38412493f00d9583b3372a",
            "6cbd6d3af738467492fae31996322834",
            "4dfe6bc6e48e474ebe9013334d921e7a",
            "b2358818c70242c3b3a189b84e3bde36",
            "8d3e0a2e17b244a2925376e1f3bf2cea",
            "f1405c39e47b4374871be1dd6ae7200e",
            "1d5a6fc645cf43c2a6d51eade6131081",
            "d114b140dfbd4d1f90776ae26fe9d957",
            "11df36c816294d2e99524fc9b355b8dd",
            "f7c86542c9f14cdb90456153a84703b2",
            "c3003a1281c9437798886a178e5eb4fe",
            "b5ab99fd723449b08e49ea4672c75849",
            "7fdefd3b8aca4fd2bf9ce0f965a94610",
            "a0dbea29f2ca45bdbe96c6bccbc16a7b"
          ]
        },
        "id": "2r7bPplxcM2k",
        "outputId": "9799adec-e76a-4673-f4c4-e10c65a2e41b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7db5077b9b374aa7a7588d797c0e0e71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "382c7ba3816748cea52577961a8f3fb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3ce3b0149b3409e8b2666aa49a026aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b27d19f7bcc84b0d955b72151e3e52b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87ed5880ccb643718b82a044576e972f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "787a2cfc3134492ba17c9d61aa1cb1cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2358818c70242c3b3a189b84e3bde36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def swap_instruction_output(json_file, output_file):\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    swapped_data = []\n",
        "    for item in data:\n",
        "        swapped_data.append({\n",
        "            \"instruction\": item[\"output\"],\n",
        "            \"input\": item[\"input\"],\n",
        "            \"output\": item[\"instruction\"]\n",
        "        })\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(swapped_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "swap_instruction_output('instructions.json', 'swapped_instructions.json')"
      ],
      "metadata": {
        "id": "Ss6zjXWefePp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_answer_text2(data):\n",
        "    cleaned_data = []\n",
        "    for item in data:\n",
        "        output = item[\"output\"]\n",
        "\n",
        "        cleaned_answer = output.replace(\"Based on the following passage: \", \"\").replace(\", provide an accurate and relevant question.\", \"\").strip()\n",
        "\n",
        "        cleaned_item = {\n",
        "            \"instruction\": item[\"instruction\"],\n",
        "            \"input\": item[\"input\"],\n",
        "            \"output\": cleaned_answer\n",
        "        }\n",
        "        cleaned_data.append(cleaned_item)\n",
        "    return cleaned_data\n",
        "\n",
        "\n",
        "def process_json_file3(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    cleaned_data = clean_answer_text2(data)\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(cleaned_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "process_json_file3(\"swapped_instructions.json\", \"final.json\")"
      ],
      "metadata": {
        "id": "fpVj9nCTfjhq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning"
      ],
      "metadata": {
        "id": "YfXaCUW5fykS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEVRxMsbf03r",
        "outputId": "5581a5e9-866a-4296-b276-9c4a47e75ee5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LLaMA-Factory' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LLaMA-Factory/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RiWgdRgngBqu",
        "outputId": "a7f81bad-1c4b-486c-9da0-26a668056dd3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n",
            "Requirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.51.3)\n",
            "Requirement already satisfied: datasets<=3.5.0,>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: accelerate<=1.6.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: peft<=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.9.6)\n",
            "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.21.1)\n",
            "Requirement already satisfied: gradio<=5.25.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (5.25.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.14.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (5.29.4)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.34.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.115.12)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.3.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (1.26.4)\n",
            "Requirement already satisfied: pydantic<=2.10.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (2.10.6)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (2.2.2)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (14.3.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (0.11.0)\n",
            "Requirement already satisfied: tyro<0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.8.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (0.30.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (4.9.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (3.10.16)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (11.1.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.11.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (4.13.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (15.0.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->-r requirements.txt (line 13)) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->-r requirements.txt (line 13)) (0.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (2.8.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->-r requirements.txt (line 17)) (3.0.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 18)) (4.9.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->-r requirements.txt (line 22)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->-r requirements.txt (line 22)) (2.27.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 25)) (1.1.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->-r requirements.txt (line 26)) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->-r requirements.txt (line 26)) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->-r requirements.txt (line 26)) (1.7.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->-r requirements.txt (line 2)) (1.20.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 25)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 25)) (4.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 16)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 26)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 26)) (2.18.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 25)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 25)) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.25.0,>=4.38.0->-r requirements.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 25)) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 26)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddxxQ4rWgG4W",
        "outputId": "da69b4ee-c12f-46cd-a85c-9ef4559b3e0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llamafactory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hT-GgrNDiclu",
        "outputId": "7e642eaa-1120-405a-aac9-2b8d6af23088"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llamafactory\n",
            "  Downloading llamafactory-0.9.2-py3-none-any.whl.metadata (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.49.0,>=4.41.2 (from llamafactory)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets<=3.2.0,>=2.16.0 (from llamafactory)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting accelerate<=1.2.1,>=0.34.0 (from llamafactory)\n",
            "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting peft<=0.12.0,>=0.11.1 (from llamafactory)\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.9.6)\n",
            "Collecting tokenizers<=0.21.0,>=0.19.0 (from llamafactory)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting gradio<=5.21.0,>=4.38.0 (from llamafactory)\n",
            "  Downloading gradio-5.21.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from llamafactory) (1.14.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from llamafactory) (5.29.4)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.34.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from llamafactory) (2.10.6)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.115.12)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.11/dist-packages (from llamafactory) (2.3.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory) (3.10.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from llamafactory) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from llamafactory) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory) (1.26.4)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from llamafactory) (14.3.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.11.0)\n",
            "Requirement already satisfied: tyro<0.9.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory) (0.8.14)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.2.1,>=0.34.0->llamafactory) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.2.1,>=0.34.0->llamafactory) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.2.1,>=0.34.0->llamafactory) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.2.1,>=0.34.0->llamafactory) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (0.70.16)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.2.0,>=2.16.0->llamafactory)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.2.0,>=2.16.0->llamafactory) (3.11.15)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio<=5.21.0,>=4.38.0->llamafactory)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (4.9.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.5.0)\n",
            "Collecting gradio-client==1.7.2 (from gradio<=5.21.0,>=4.38.0->llamafactory)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio<=5.21.0,>=4.38.0->llamafactory)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (3.10.16)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (11.1.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.11.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.21.0,>=4.38.0->llamafactory) (4.13.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio<=5.21.0,>=4.38.0->llamafactory) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->llamafactory) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->llamafactory) (2.27.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.49.0,>=4.41.2->llamafactory) (2024.11.6)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory) (1.7.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory) (0.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->llamafactory) (3.0.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory) (1.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory) (1.20.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.21.0,>=4.38.0->llamafactory) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.21.0,>=4.38.0->llamafactory) (1.0.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->llamafactory) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->llamafactory) (4.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.2.0,>=2.16.0->llamafactory) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.2.0,>=2.16.0->llamafactory) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory) (2.18.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->llamafactory) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate<=1.2.1,>=0.34.0->llamafactory) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory) (0.1.2)\n",
            "Downloading llamafactory-0.9.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.8/279.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.21.0-py3-none-any.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Installing collected packages: markupsafe, fsspec, aiofiles, tokenizers, gradio-client, transformers, gradio, datasets, accelerate, peft, llamafactory\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.8.0\n",
            "    Uninstalling gradio_client-1.8.0:\n",
            "      Successfully uninstalled gradio_client-1.8.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.25.0\n",
            "    Uninstalling gradio-5.25.0:\n",
            "      Successfully uninstalled gradio-5.25.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 3.5.0\n",
            "    Uninstalling datasets-3.5.0:\n",
            "      Successfully uninstalled datasets-3.5.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.2.1 aiofiles-23.2.1 datasets-3.2.0 fsspec-2024.9.0 gradio-5.21.0 gradio-client-1.7.2 llamafactory-0.9.2 markupsafe-2.1.5 peft-0.12.0 tokenizers-0.21.0 transformers-4.49.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!GRADIO_SHARE=1 llamafactory-cli webui"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0DAeIDTirzy",
        "outputId": "0dee9e4b-2df6-404d-bb0a-b4582c955129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-25 20:04:13.497536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745611453.517689    2895 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745611453.523619    2895 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-25 20:04:13.543679: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://d7550f5b9d0a8140a3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "2025-04-25 20:07:40.988632: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745611661.012357    3778 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745611661.019188    3778 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[INFO|2025-04-25 20:07:48] llamafactory.hparams.parser:384 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.float16\n",
            "config.json: 100% 736/736 [00:00<00:00, 4.09MB/s]\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:07:48,795 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:07:48,797 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer_config.json: 100% 237/237 [00:00<00:00, 2.03MB/s]\n",
            "vocab.json: 100% 798k/798k [00:03<00:00, 201kB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 3.12MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 28.7MB/s]\n",
            "added_tokens.json: 100% 1.08k/1.08k [00:00<00:00, 8.78MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 856kB/s]\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:54,501 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:54,501 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:54,501 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:54,501 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:54,502 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:54,502 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:54,502 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:07:55,318 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:07:55,319 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:55,410 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:55,410 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:55,410 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:55,411 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:55,411 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:55,411 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:07:55,411 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|2025-04-25 20:07:55] llamafactory.data.template:157 >> Add pad token: <|endoftext|>\n",
            "[INFO|2025-04-25 20:07:55] llamafactory.data.loader:157 >> Loading dataset final.json...\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 18 examples [00:00, 217.33 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 18/18 [00:00<00:00, 33.84 examples/s]\n",
            "Running tokenizer on dataset (num_proc=16):   0% 0/18 [00:00<?, ? examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:07:58,653 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3864 > 2048). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:07:59,000 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3864 > 2048). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:07:59,086 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3929 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  28% 5/18 [00:02<00:04,  2.84 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:07:59,606 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3929 > 2048). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:07:59,604 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3712 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  33% 6/18 [00:02<00:04,  2.87 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:00,053 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3712 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  44% 8/18 [00:02<00:03,  3.31 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:00,383 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3712 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  50% 9/18 [00:03<00:02,  3.18 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:00,866 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3616 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  56% 10/18 [00:03<00:02,  3.14 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:01,197 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3616 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  61% 11/18 [00:03<00:02,  3.25 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:01,304 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3692 > 2048). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:01,453 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3616 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  67% 12/18 [00:04<00:01,  3.49 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:01,611 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3692 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16):  78% 14/18 [00:04<00:00,  4.94 examples/s][WARNING|tokenization_utils_base.py:3945] 2025-04-25 20:08:01,789 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3692 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Running tokenizer on dataset (num_proc=16): 100% 18/18 [00:04<00:00,  3.85 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[20490, 25, 383, 47038, 3918, 443, 318, 257, 636, 286, 262, 3989, 286, 11711, 12933, 352, 300, 16, 12, 3106, 599, 945, 72, 269, 341, 286, 2568, 12213, 30, 198, 48902, 25, 470, 14363, 4538, 373, 5597, 1262, 262, 47038, 3918, 443, 16686, 284, 262, 3989, 286, 11711, 12933, 352, 300, 16, 12, 3106, 599, 945, 72, 269, 341, 286, 2568, 12213, 287, 15014, 1329, 88, 19789, 12, 15808, 31643, 12334, 12410, 9517, 78, 6437, 5362, 16, 11, 288, 615, 485, 39990, 48669, 16, 88, 392, 290, 21468, 12379, 374, 261, 354, 16, 352, 38942, 10672, 286, 8705, 290, 3518, 19838, 11, 6403, 286, 5366, 23427, 11, 523, 1558, 352, 50007, 11, 5366, 23427, 11, 16503, 13239, 357, 47844, 31383, 26, 15556, 31383, 26, 6292, 31383, 8, 287, 428, 3348, 11, 599, 45826, 12, 16963, 10720, 20683, 7605, 389, 9322, 284, 3557, 7246, 12, 269, 453, 5911, 422, 1366, 5981, 1333, 23876, 12213, 1022, 953, 282, 8573, 287, 1588, 9426, 263, 5116, 12, 3106, 4981, 286, 734, 12, 19577, 15014, 1329, 88, 12334, 82, 13, 262, 3164, 11073, 287, 12, 1059, 5310, 540, 11, 29877, 306, 12, 15236, 4981, 326, 22919, 262, 2656, 6382, 605, 9172, 379, 257, 881, 2793, 31350, 1575, 11, 355, 7380, 1333, 23876, 12213, 761, 284, 307, 16726, 13, 262, 1994, 3895, 286, 262, 3164, 318, 326, 11410, 12213, 389, 6163, 25735, 422, 262, 4610, 286, 257, 24748, 87, 6436, 5612, 1917, 11, 351, 257, 3748, 4610, 11, 290, 645, 257, 3161, 72, 14895, 319, 262, 4645, 286, 5046, 12213, 389, 2672, 13, 356, 10176, 428, 3164, 319, 4981, 286, 734, 12, 19577, 19789, 12, 15808, 31643, 12334, 379, 302, 2047, 10119, 1271, 302, 28, 362, 190, 13464, 11, 810, 334, 312, 6268, 318, 23458, 13, 284, 1833, 262, 2597, 286, 262, 850, 13200, 7736, 1417, 329, 262, 9426, 263, 5116, 20128, 319, 599, 45826, 9695, 11, 356, 2074, 734, 4172, 286, 4981, 6492, 422, 734, 2566, 304, 1156, 953, 282, 26969, 9150, 7605, 13, 262, 374, 301, 3544, 2568, 12, 8738, 4402, 1774, 29617, 519, 20996, 26969, 9150, 12881, 11, 981, 262, 1218, 3544, 12881, 24969, 803, 379, 257, 2060, 8373, 6492, 422, 28810, 46287, 5277, 6121, 286, 262, 12334, 47787, 13, 356, 905, 326, 11, 287, 1111, 2663, 11, 290, 3805, 645, 257, 12, 3448, 10145, 3518, 3725, 318, 16560, 656, 262, 3164, 11, 5981, 12213, 1973, 262, 18911, 286, 12881, 389, 1852, 72, 1225, 287, 4381, 351, 262, 2938, 4286, 286, 5046, 12213, 287, 734, 12, 38517, 47741, 13, 1865, 11, 8904, 13204, 2458, 287, 262, 10375, 3912, 290, 257, 5554, 48668, 2566, 304, 1156, 599, 45826, 389, 6515, 13, 3443, 11, 3584, 407, 3264, 20326, 287, 262, 8771, 11, 262, 599, 945, 72, 1225, 4981, 423, 6275, 890, 12, 4354, 10159, 6608, 290, 9380, 22919, 262, 15246, 952, 12, 11498, 35738, 6954, 286, 11410, 12334, 8573, 287, 262, 31643, 13, 352, 13, 9793, 287, 262, 15993, 6764, 286, 4166, 42291, 12334, 82, 357, 75, 388, 1636, 13521, 26, 26850, 5878, 26, 474, 320, 207, 551, 8471, 2864, 828, 2568, 318, 11172, 1973, 262, 18911, 286, 24870, 8573, 2884, 1729, 29127, 1333, 23876, 12213, 13, 16992, 287, 428, 4286, 318, 262, 1109, 326, 407, 477, 12213, 423, 262, 976, 6817, 11, 475, 484, 3051, 287, 47136, 7572, 13, 287, 1109, 11, 7667, 29052, 2370, 5644, 326, 262, 1729, 29127, 10375, 3912, 1871, 24870, 8573, 318, 29877, 13, 262, 6954, 286, 8573, 379, 257, 1728, 4129, 5046, 8338, 20736, 2402, 257, 24637, 286, 477, 584, 8573, 357, 74, 430, 488, 12647, 16382, 26, 11752, 15813, 3216, 6303, 26, 865, 21612, 333, 1222, 356, 72, 9162, 8, 290, 262, 287, 334, 594, 286, 12213, 351, 262, 32150, 900, 286, 8573, 460, 307, 4143, 24007, 351, 4159, 3298, 304, 46080, 82, 13, 4388, 6370, 284, 5678, 257, 5322, 900, 286, 27490, 326, 14561, 428, 599, 45826, 423, 587, 925, 287, 262, 1613, 11, 1690, 329, 40091, 4903, 908, 1678, 810, 1333, 23876, 12213, 389, 29801, 11068, 287, 46287, 5277, 2272, 290, 1262, 257, 36076, 12, 2164, 1328, 18398, 278, 286, 331, 12888, 2209, 329, 22440, 25, 288, 615, 485, 13, 39990, 48669, 31, 82, 18970, 13, 936, 13, 334, 21070, 87, 452, 25, 13330, 13, 657, 3553, 2623, 85, 17, 685, 746, 23154, 13, 6562, 12, 67, 2047, 60, 2242, 474, 377, 12131, 362, 374, 13, 6437, 5362, 11, 288, 13, 39990, 48669, 290, 257, 13, 12379, 374, 261, 354, 262, 18911, 286, 16252, 13, 300, 9226, 2123, 435, 13, 357, 18946, 8, 3177, 734, 12, 19577, 3488, 32269, 49240, 47741, 290, 4166, 257, 5322, 900, 286, 18064, 13027, 2566, 304, 1156, 498, 27490, 15030, 262, 6954, 286, 262, 1588, 290, 1402, 16252, 13, 287, 428, 2746, 11, 691, 11410, 2846, 547, 17383, 1912, 319, 13050, 422, 1277, 29052, 18640, 13, 351, 262, 3061, 286, 13720, 7531, 11701, 10238, 3355, 47741, 11, 294, 16911, 2123, 435, 13, 357, 4626, 8, 4166, 1729, 29127, 5322, 4981, 286, 6614, 2284, 5857, 12334, 3264, 422, 262, 15030, 27490, 416, 374, 301, 18398, 278, 262, 12334, 656, 257, 4269, 3083, 12, 8770, 1886, 1612, 290, 257, 22146, 333, 12, 275, 341, 18441, 11, 290, 788, 17985, 278, 1729, 29127, 12213, 1871, 262, 4269, 3083, 15874, 22146, 5945, 602, 11, 1312, 13, 304, 13, 262, 22146, 5945, 341, 12, 11766, 5945, 341, 1729, 29127, 414, 357, 400, 16911, 2123, 435, 13, 1946, 737, 262, 4981, 7907, 880, 12, 27718, 4836, 12, 22853, 461, 6382, 605, 3033, 286, 3355, 47741, 290, 663, 7869, 287, 257, 2653, 15208, 304, 202, 3456, 9355, 13, 262, 4981, 635, 12605, 42291, 17262, 866, 284, 10926, 369, 308, 20074, 810, 12213, 1022, 262, 4269, 3083, 1612, 12334, 290, 691, 530, 2060, 4269, 3083, 2082, 574, 4494, 389, 17383, 13, 618, 5322, 12, 2875, 6382, 605, 24612, 389, 10944, 1262, 9426, 263, 5116, 20128, 319, 257, 1877, 12, 19577, 850, 13200, 1852, 72, 1225, 416, 257, 900, 286, 953, 282, 8573, 357, 69, 29257, 12844, 26, 5752, 1636, 1222, 288, 707, 1559, 2177, 828, 1333, 23876, 12213, 389, 29801, 9713, 287, 953, 282, 2272, 416, 17247, 257, 2368, 12, 2875, 763, 68, 202, 3456, 11192, 273, 21539, 422, 20128, 286, 262, 4308, 2163, 319, 262, 24748, 14070, 3381, 286, 262, 6812, 959, 12, 301, 3369, 27490, 357, 3919, 441, 2123, 435, 13, 3648, 11, 2813, 737, 599, 45826, 9695, 423, 635, 587, 6515, 287, 428, 5322, 12, 2875, 4634, 13, 3155, 83, 2123, 435, 13, 357, 16088, 8, 12006, 9426, 263, 5116, 4981, 286, 262, 11266, 42291, 12334, 1613, 257, 19528, 12, 29532, 2239, 1262, 1774, 29617, 519, 20996, 26969, 9150, 357, 33320, 8, 12881, 357, 75, 388, 1636, 8069, 26, 264, 7058, 49547, 12923, 8, 290, 6515, 326, 262, 2568, 4351, 3912, 287, 953, 282, 2272, 7303, 867, 6608, 351, 663, 11283, 287, 31624, 1773, 291, 3488, 32269, 1115, 12, 19577, 42291, 12334, 82, 357, 5948, 2150, 2123, 435, 13, 8735, 737, 329, 4554, 11, 262, 7035, 6515, 326, 12213, 389, 1957, 287, 953, 282, 2272, 290, 326, 257, 1277, 2568, 44847, 7160, 13, 15075, 3481, 11, 816, 79, 2232, 1222, 277, 48038, 357, 22666, 257, 8, 11068, 262, 1176, 4466, 286, 24573, 12881, 287, 257, 35577, 18645, 7679, 290, 6515, 326, 12213, 287, 953, 282, 2272, 3051, 20736, 1022, 1333, 5643, 286, 12881, 3025, 2160, 286, 953, 282, 36525, 318, 4961, 284, 6632, 11, 2092, 284, 2568, 12213, 1022, 46287, 5277, 12881, 287, 3488, 32269, 47741, 13, 2158, 11, 15993, 2746, 1502, 7741, 7605, 357, 808, 1636, 1222, 288, 707, 1559, 2177, 8, 423, 407, 16083, 21514, 428, 3895, 13, 287, 1109, 11, 618, 953, 282, 26969, 1930, 1756, 884, 355, 24573, 389, 9322, 11, 42255, 12, 15236, 4981, 389, 3221, 6492, 11, 355, 262, 2368, 12, 2875, 763, 68, 202, 3456, 11192, 273, 318, 15715, 357, 72, 13, 304, 13, 749, 763, 68, 202, 35611, 389, 2566, 304, 1156, 422, 6632, 8, 329, 25783, 296, 32269, 12334, 82, 1231, 1948, 23606, 316, 1678, 13, 428, 16222, 364, 262, 10794, 286, 262, 10238, 11887, 286, 16252, 12213, 290, 5732, 31350, 3484, 11, 1201, 477, 1333, 23876, 12213, 423, 284, 307, 16726, 329, 19988, 262, 2746, 2651, 287, 640, 13, 262, 374, 301, 10156, 286, 428, 670, 318, 326, 356, 18077, 284, 4174, 1366, 12, 15808, 7605, 357, 2436, 388, 1222, 42392, 1636, 8309, 26, 45033, 1122, 2123, 435, 13, 1584, 26, 2376, 786, 559, 1222, 45033, 1122, 2864, 26, 45033, 1122, 2123, 435, 13, 13130, 8, 355, 257, 1724, 284, 5911, 5981, 1333, 23876, 12213, 287, 9426, 263, 5116, 4981, 286, 42291, 12334, 82, 13, 674, 4031, 318, 284, 7716, 5322, 1502, 4981, 31038, 257, 3094, 2837, 286, 16252, 981, 23934, 31350, 304, 202, 979, 1387, 290, 6179, 1799, 416, 778, 46493, 4939, 12213, 326, 389, 407, 5981, 329, 262, 17262, 13, 262, 39774, 286, 262, 5150, 3164, 318, 75, 16, 12, 16338, 1417, 20683, 357, 25520, 805, 2123, 435, 13, 3648, 26, 256, 571, 1477, 343, 3216, 2211, 828, 6768, 973, 287, 262, 13905, 2055, 284, 7925, 13544, 20473, 699, 10552, 286, 3716, 40522, 7268, 257, 24637, 286, 45718, 3033, 13, 262, 1729, 12, 10989, 304, 1156, 3379, 11, 1865, 24748, 87, 11, 3450, 286, 262, 75, 16, 16338, 5612, 3578, 25449, 262, 10375, 6356, 1917, 656, 257, 24748, 87, 6436, 5612, 1917, 326, 460, 307, 16019, 304, 202, 979, 1473, 11, 351, 257, 3748, 4610, 13, 1201, 645, 257, 3161, 72, 3725, 286, 262, 17262, 318, 7736, 1417, 11, 262, 3164, 318, 497, 12, 2164, 1328, 290, 5981, 12213, 389, 1852, 72, 1225, 287, 257, 4235, 12, 1525, 12, 14171, 6977, 1973, 262, 18911, 286, 12881, 13, 599, 45826, 12, 16963, 10720, 20683, 7605, 423, 587, 2904, 5150, 416, 45033, 1122, 290, 9949, 329, 7035, 513, 38945, 357, 1671, 403, 1122, 2123, 435, 13, 1584, 26, 38387, 5847, 2123, 435, 13, 2864, 8, 287, 262, 264, 521, 88, 9355, 357, 82, 29572, 1852, 72, 269, 341, 286, 1729, 29127, 17262, 828, 355, 257, 1724, 284, 7073, 13544, 20473, 699, 6382, 605, 24612, 286, 3341, 3025, 10238, 357, 4360, 7104, 8, 6954, 27490, 389, 29877, 287, 262, 2272, 286, 1744, 5499, 357, 1671, 403, 1122, 2123, 435, 13, 1584, 737, 674, 670, 1614, 32820, 422, 777, 304, 393, 912, 287, 262, 6650, 13, 618, 34391, 287, 13027, 2566, 304, 1156, 498, 1296, 11, 262, 6812, 959, 12, 301, 3369, 27490, 329, 13352, 601, 856, 12334, 82, 389, 5600, 2878, 20221, 29877, 11, 355, 691, 1178, 2846, 1391, 24748, 596, 11, 31116, 516, 2566, 514, 295, 290, 3833, 3386, 284, 45075, 2347, 1391, 8277, 284, 262, 4045, 29163, 13, 2158, 11, 618, 9426, 263, 5116, 4981, 389, 10944, 11, 884, 13204, 599, 45826, 318, 4143, 2626, 13, 644, 318, 17232, 318, 262, 599, 45826, 287, 262, 10375, 3912, 1022, 16252, 286, 6268, 326, 25457, 257, 34319, 72, 287, 42291, 1103, 38189, 13, 17640, 11, 356, 4031, 284, 14561, 428, 3895, 290, 1233, 359, 257, 2878, 20221, 29877, 2746, 326, 8186, 728, 262, 2656, 9172, 13, 287, 3090, 11, 599, 45826, 1852, 72, 269, 341, 5050, 423, 587, 5625, 11, 523, 1290, 11, 284, 5365, 1402, 9426, 263, 5116, 4981, 357, 5439, 786, 559, 1222, 45033, 1122, 2864, 828, 290, 340, 318, 407, 1865, 7247, 611, 777, 460, 307, 7736, 1417, 284, 5911, 290, 7925, 5981, 12213, 287, 4025, 4981, 287, 4381, 351, 262, 4920, 4286, 286, 2568, 12213, 287, 42291, 12334, 82, 13, 287, 428, 2565, 11, 674, 3164, 318, 5699, 284, 262, 2274, 670, 286, 299, 958, 1222, 256, 958, 64, 357, 4626, 828, 256, 958, 64, 2123, 435, 13, 357, 5304, 8, 290, 299, 958, 2123, 435, 13, 357, 7908, 737, 777, 7035, 9322, 3127, 12, 1169, 9997, 291, 599, 945, 72, 269, 341, 10581, 357, 3605, 805, 2864, 8, 284, 5911, 1994, 42726, 12, 1462, 12, 85, 26158, 12213, 287, 734, 12, 19577, 3488, 32269, 47741, 11, 16727, 29877, 4981, 326, 8006, 262, 6393, 11887, 286, 15014, 1329, 88, 334, 312, 12334, 351, 257, 5322, 1271, 286, 12213, 1022, 262, 976, 1588, 1271, 286, 2585, 13, 262, 1218, 10156, 286, 428, 3348, 318, 326, 356, 10716, 703, 599, 45826, 286, 2568, 12213, 8338, 319, 262, 850, 13200, 973, 284, 7716, 262, 9426, 263, 5116, 2746, 13, 4917, 281, 5035, 850, 13200, 329, 20128, 318, 20915, 355, 257, 9389, 4876, 357, 3919, 441, 2123, 435, 13, 1584, 828, 290, 1811, 953, 282]\n",
            "inputs:\n",
            "Human: The latex style le is a part of the journal of fluid mechanics 1 l1-based sparsi cation of energy interactions?\n",
            "Assistant:'this draft was prepared using the latex style le belonging to the journal of fluid mechanics 1 l1-based sparsi cation of energy interactions in unsteady lid-driven cavity ow riccardo rubini1, davide lasagna1yand andrea da ronch1 1faculty of engineering and physical sciences, university of southampton, so17 1bj, southampton, united kingdom (received xx; revised xx; accepted xx) in this paper, sparsity-promoting regression techniques are employed to automati- cally identify from data relevant triadic interactions between modal structures in large galerkin-based models of two-dimensional unsteady ows. the approach produces in- terpretable, sparsely-connected models that reproduce the original dynamical behaviour at a much lower computational cost, as fewer triadic interactions need to be evaluated. the key feature of the approach is that dominant interactions are selected systematically from the solution of a convex optimisation problem, with a unique solution, and no a priori assumptions on the structure of scale interactions are required. we demonstrate this approach on models of two-dimensional lid-driven cavity ow at reynolds number re= 2\u0002104, where uid motion is chaotic. to understand the role of the subspace utilised for the galerkin projection on sparsity characteristics, we consider two families of models obtained from two di erent modal decomposition techniques. the rst uses energy-optimal proper orthogonal decomposition modes, while the second uses modes oscillating at a single frequency obtained from discrete fourier transform of the ow snapshots. we show that, in both cases, and despite no a-priori physical knowledge is incorporated into the approach, relevant interactions across the hierarchy of modes are identi ed in agreement with the expected picture of scale interactions in two- dimensional turbulence. yet, substantial structural changes in the interaction pattern and a quantitatively di erent sparsity are observed. finally, although not directly enforced in the procedure, the sparsi ed models have excellent long-term stability properties and correctly reproduce the spatio-temporal evolution of dominant ow structures in the cavity. 1. introduction in the classical description of developed turbulent ows (lumley 1979; pope 2001; jim\u0013 enez 2018), energy is transferred across the hierarchy of coherent structures via nonlinear triadic interactions. implicit in this picture is the fact that not all interactions have the same importance, but they occur in preferential patterns. in fact, extensive numerical evidence suggests that the nonlinear interaction pattern among coherent structures is sparse. the evolution of structures at a certain length scale depends predominantly upon a subset of all other structures (kraichnan 1971; ohkitani 1990; brasseur & wei 1994) and the in uence of interactions with the complementary set of structures can be generally neglected with minor global e ects. successful attempts to construct a reduced set of equations that exploit this sparsity have been made in the past, often for canonical geometries where triadic interactions are conveniently examined in fourier space and using a coarse-grained partitioning of yemail address for correspondence: davide. lasagna@soton. ac. ukarxiv:2006. 05736v2 [physics. flu-dyn] 23 jul 2020 2 r. rubini, d. lasagna and a. da ronch the hierarchy of scales. laval et al. (1999) considered two-dimensional homogeneous decaying turbulence and developed a reduced set of coupled partial di erential equations governing the evolution of the large and small scales. in this model, only dominant terms were retained based on observations from direct numerical simulation. with the goal of identifying fundamental mechanisms underlying wall turbulence, thomas et al. (2015) developed nonlinear reduced models of plane couette ow directly from the governing equations by rst partitioning the ow into a streamwise-averaged mean and a pertur- bation eld, and then neglecting nonlinear interactions among the streamwise varying perturbations, i. e. the perturbation-perturbation nonlinearity (thomas et al. 2014). the models captured well-established roll-streak dynamical features of wall turbulence and its statistics in a computationally e\u000ecient framework. the models also sustained turbulent dynamics down to minimal con gurations where interactions between the streamwise mean ow and only one single streamwise wavenumber are retained. when reduced-order dynamical representations are derived using galerkin projection on a low-dimensional subspace identi ed by a set of modal structures (fletcher 1984; rowley & dawson 2017), triadic interactions are conveniently studied in modal space by examining a third-order coe\u000ecient tensor arising from projection of the basis function on the convective term of the navier-stokes equations (noack et al. 2008, 2011). sparsity characteristics have also been observed in this reduced-order setting. couplet et al. (2003) constructed galerkin models of the separated turbulent ow past a backward-facing step using proper orthogonal decomposition (pod) modes (lumley 1970; sirovich 1987) and observed that the energy transfer pattern in modal space shares many properties with its counterpart in isotropic homogeneous three-dimensional turbulent ows (yeung et al. 1995). for instance, the authors observed that interactions are local in modal space and that a direct energy cascade exists. analogously, rempfer & fasel (1994 a) examined the power budget of pod modes in a transitional boundary layer and observed that interactions in modal space occur predominantly between triads of modes whose sum of modal indices is equal to zero, similar to energy interactions between fourier modes in homogeneous turbulence. however, classical model order reduction techniques (rowley & dawson 2017) have not traditionally exploited this feature. in fact, when modal decompositions such as pod are employed, densely-connected models are usually obtained, as the third-order coe\u000ecient tensor is dense (i. e. most coe\u000ecients are di erent from zero) for inhomogeneous ows without particular symmetries. this hinders the interpretation of the underlying physics of scales interactions and increases computational costs, since all triadic interactions have to be evaluated for advancing the model forward in time. the rst contribution of this work is that we propose to apply data-driven techniques (blum & langley 1997; brunton et al. 2016; loiseau & brunton 2018; brunton et al. 2019) as a means to identify relevant triadic interactions in galerkin models of turbulent ows. our aim is to generate reduced order models resolving a wide range of scales while preserving computational e\u000eciency and interpretability by pruning weak interactions that are not relevant for the dynamics. the cornerstone of the proposed approach isl1-regularised regression (friedman et al. 2008; tibshirani 2013), widely used in the statistical community to extract parsimonious representation of complex datasets containing a subset of predominant features. the non-di erentiable, yet convex, nature of thel1regularisation allows transforming the interaction selection problem into a convex optimisation problem that can be solved e\u000eciently, with a unique solution. since no a priori knowledge of the dynamics is utilised, the approach is ne-grained and relevant interactions are identi ed in a mode-by-mode fashion across the hierarchy of modes. sparsity-promoting regression techniques have been recently proposed by brunton and guidelines for authors 3 coworkers (brunton et al. 2016; kaiser et al. 2018) in the sindy framework (sparse identi cation of nonlinear dynamics), as a means to discover parsimonious dynamical representations of systems whose underlying (but hidden) evolution equations are sparse in the space of possible functions (brunton et al. 2016). our work deviates from these e orts in the perspective. when formulated in partial di erential form, the navier-stokes equations for incompressible ows are indeed structurally sparse, as only few terms { convection, viscous di usion and pressure forces to conserve mass { participate to the overall equilibrium. however, when galerkin models are derived, such structural sparsity is generally lost. what is preserved is the sparsity in the interaction pattern between scales of motion that emerges a posteriori in turbulent realisations. fundamentally, we aim to exploit this feature and distill a structurally sparse model that reproduces the original behaviour. in addition, sparsity identi cation methods have been applied, so far, to relatively small galerkin models (loiseau & brunton 2018), and it is not yet understood if these can be utilised to identify and extract relevant interactions in larger models in agreement with the established picture of energy interactions in turbulent ows. in this sense, our approach is closer to the recent work of nair & taira (2015), taira et al. (2016) and nair et al. (2018). these authors employed network-theoretic sparsi cation approaches (newman 2018) to identify key vortex-to-vortex interactions in two-dimensional homogeneous turbulence, obtaining sparse models that capture the essential physics of unsteady uid ow with a reduced number of interactions between the same large number of states. the second contribution of this paper is that we examine how sparsity of energy interactions depends on the subspace used to generate the galerkin model. finding an appropriate subspace for projection is recognised as a challenging task (noack et al. 2016), and several modal\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 470, 14363, 4538, 373, 5597, 1262, 262, 47038, 3918, 443, 16686, 284, 262, 3989, 286, 11711, 12933, 352, 300, 16, 12, 3106, 599, 945, 72, 269, 341, 286, 2568, 12213, 287, 15014, 1329, 88, 19789, 12, 15808, 31643, 12334, 12410, 9517, 78, 6437, 5362, 16, 11, 288, 615, 485, 39990, 48669, 16, 88, 392, 290, 21468, 12379, 374, 261, 354, 16, 352, 38942, 10672, 286, 8705, 290, 3518, 19838, 11, 6403, 286, 5366, 23427, 11, 523, 1558, 352, 50007, 11, 5366, 23427, 11, 16503, 13239, 357, 47844, 31383, 26, 15556, 31383, 26, 6292, 31383, 8, 287, 428, 3348, 11, 599, 45826, 12, 16963, 10720, 20683, 7605, 389, 9322, 284, 3557, 7246, 12, 269, 453, 5911, 422, 1366, 5981, 1333, 23876, 12213, 1022, 953, 282, 8573, 287, 1588, 9426, 263, 5116, 12, 3106, 4981, 286, 734, 12, 19577, 15014, 1329, 88, 12334, 82, 13, 262, 3164, 11073, 287, 12, 1059, 5310, 540, 11, 29877, 306, 12, 15236, 4981, 326, 22919, 262, 2656, 6382, 605, 9172, 379, 257, 881, 2793, 31350, 1575, 11, 355, 7380, 1333, 23876, 12213, 761, 284, 307, 16726, 13, 262, 1994, 3895, 286, 262, 3164, 318, 326, 11410, 12213, 389, 6163, 25735, 422, 262, 4610, 286, 257, 24748, 87, 6436, 5612, 1917, 11, 351, 257, 3748, 4610, 11, 290, 645, 257, 3161, 72, 14895, 319, 262, 4645, 286, 5046, 12213, 389, 2672, 13, 356, 10176, 428, 3164, 319, 4981, 286, 734, 12, 19577, 19789, 12, 15808, 31643, 12334, 379, 302, 2047, 10119, 1271, 302, 28, 362, 190, 13464, 11, 810, 334, 312, 6268, 318, 23458, 13, 284, 1833, 262, 2597, 286, 262, 850, 13200, 7736, 1417, 329, 262, 9426, 263, 5116, 20128, 319, 599, 45826, 9695, 11, 356, 2074, 734, 4172, 286, 4981, 6492, 422, 734, 2566, 304, 1156, 953, 282, 26969, 9150, 7605, 13, 262, 374, 301, 3544, 2568, 12, 8738, 4402, 1774, 29617, 519, 20996, 26969, 9150, 12881, 11, 981, 262, 1218, 3544, 12881, 24969, 803, 379, 257, 2060, 8373, 6492, 422, 28810, 46287, 5277, 6121, 286, 262, 12334, 47787, 13, 356, 905, 326, 11, 287, 1111, 2663, 11, 290, 3805, 645, 257, 12, 3448, 10145, 3518, 3725, 318, 16560, 656, 262, 3164, 11, 5981, 12213, 1973, 262, 18911, 286, 12881, 389, 1852, 72, 1225, 287, 4381, 351, 262, 2938, 4286, 286, 5046, 12213, 287, 734, 12, 38517, 47741, 13, 1865, 11, 8904, 13204, 2458, 287, 262, 10375, 3912, 290, 257, 5554, 48668, 2566, 304, 1156, 599, 45826, 389, 6515, 13, 3443, 11, 3584, 407, 3264, 20326, 287, 262, 8771, 11, 262, 599, 945, 72, 1225, 4981, 423, 6275, 890, 12, 4354, 10159, 6608, 290, 9380, 22919, 262, 15246, 952, 12, 11498, 35738, 6954, 286, 11410, 12334, 8573, 287, 262, 31643, 13, 352, 13, 9793, 287, 262, 15993, 6764, 286, 4166, 42291, 12334, 82, 357, 75, 388, 1636, 13521, 26, 26850, 5878, 26, 474, 320, 207, 551, 8471, 2864, 828, 2568, 318, 11172, 1973, 262, 18911, 286, 24870, 8573, 2884, 1729, 29127, 1333, 23876, 12213, 13, 16992, 287, 428, 4286, 318, 262, 1109, 326, 407, 477, 12213, 423, 262, 976, 6817, 11, 475, 484, 3051, 287, 47136, 7572, 13, 287, 1109, 11, 7667, 29052, 2370, 5644, 326, 262, 1729, 29127, 10375, 3912, 1871, 24870, 8573, 318, 29877, 13, 262, 6954, 286, 8573, 379, 257, 1728, 4129, 5046, 8338, 20736, 2402, 257, 24637, 286, 477, 584, 8573, 357, 74, 430, 488, 12647, 16382, 26, 11752, 15813, 3216, 6303, 26, 865, 21612, 333, 1222, 356, 72, 9162, 8, 290, 262, 287, 334, 594, 286, 12213, 351, 262, 32150, 900, 286, 8573, 460, 307, 4143, 24007, 351, 4159, 3298, 304, 46080, 82, 13, 4388, 6370, 284, 5678, 257, 5322, 900, 286, 27490, 326, 14561, 428, 599, 45826, 423, 587, 925, 287, 262, 1613, 11, 1690, 329, 40091, 4903, 908, 1678, 810, 1333, 23876, 12213, 389, 29801, 11068, 287, 46287, 5277, 2272, 290, 1262, 257, 36076, 12, 2164, 1328, 18398, 278, 286, 331, 12888, 2209, 329, 22440, 25, 288, 615, 485, 13, 39990, 48669, 31, 82, 18970, 13, 936, 13, 334, 21070, 87, 452, 25, 13330, 13, 657, 3553, 2623, 85, 17, 685, 746, 23154, 13, 6562, 12, 67, 2047, 60, 2242, 474, 377, 12131, 362, 374, 13, 6437, 5362, 11, 288, 13, 39990, 48669, 290, 257, 13, 12379, 374, 261, 354, 262, 18911, 286, 16252, 13, 300, 9226, 2123, 435, 13, 357, 18946, 8, 3177, 734, 12, 19577, 3488, 32269, 49240, 47741, 290, 4166, 257, 5322, 900, 286, 18064, 13027, 2566, 304, 1156, 498, 27490, 15030, 262, 6954, 286, 262, 1588, 290, 1402, 16252, 13, 287, 428, 2746, 11, 691, 11410, 2846, 547, 17383, 1912, 319, 13050, 422, 1277, 29052, 18640, 13, 351, 262, 3061, 286, 13720, 7531, 11701, 10238, 3355, 47741, 11, 294, 16911, 2123, 435, 13, 357, 4626, 8, 4166, 1729, 29127, 5322, 4981, 286, 6614, 2284, 5857, 12334, 3264, 422, 262, 15030, 27490, 416, 374, 301, 18398, 278, 262, 12334, 656, 257, 4269, 3083, 12, 8770, 1886, 1612, 290, 257, 22146, 333, 12, 275, 341, 18441, 11, 290, 788, 17985, 278, 1729, 29127, 12213, 1871, 262, 4269, 3083, 15874, 22146, 5945, 602, 11, 1312, 13, 304, 13, 262, 22146, 5945, 341, 12, 11766, 5945, 341, 1729, 29127, 414, 357, 400, 16911, 2123, 435, 13, 1946, 737, 262, 4981, 7907, 880, 12, 27718, 4836, 12, 22853, 461, 6382, 605, 3033, 286, 3355, 47741, 290, 663, 7869, 287, 257, 2653, 15208, 304, 202, 3456, 9355, 13, 262, 4981, 635, 12605, 42291, 17262, 866, 284, 10926, 369, 308, 20074, 810, 12213, 1022, 262, 4269, 3083, 1612, 12334, 290, 691, 530, 2060, 4269, 3083, 2082, 574, 4494, 389, 17383, 13, 618, 5322, 12, 2875, 6382, 605, 24612, 389, 10944, 1262, 9426, 263, 5116, 20128, 319, 257, 1877, 12, 19577, 850, 13200, 1852, 72, 1225, 416, 257, 900, 286, 953, 282, 8573, 357, 69, 29257, 12844, 26, 5752, 1636, 1222, 288, 707, 1559, 2177, 828, 1333, 23876, 12213, 389, 29801, 9713, 287, 953, 282, 2272, 416, 17247, 257, 2368, 12, 2875, 763, 68, 202, 3456, 11192, 273, 21539, 422, 20128, 286, 262, 4308, 2163, 319, 262, 24748, 14070, 3381, 286, 262, 6812, 959, 12, 301, 3369, 27490, 357, 3919, 441, 2123, 435, 13, 3648, 11, 2813, 737, 599, 45826, 9695, 423, 635, 587, 6515, 287, 428, 5322, 12, 2875, 4634, 13, 3155, 83, 2123, 435, 13, 357, 16088, 8, 12006, 9426, 263, 5116, 4981, 286, 262, 11266, 42291, 12334, 1613, 257, 19528, 12, 29532, 2239, 1262, 1774, 29617, 519, 20996, 26969, 9150, 357, 33320, 8, 12881, 357, 75, 388, 1636, 8069, 26, 264, 7058, 49547, 12923, 8, 290, 6515, 326, 262, 2568, 4351, 3912, 287, 953, 282, 2272, 7303, 867, 6608, 351, 663, 11283, 287, 31624, 1773, 291, 3488, 32269, 1115, 12, 19577, 42291, 12334, 82, 357, 5948, 2150, 2123, 435, 13, 8735, 737, 329, 4554, 11, 262, 7035, 6515, 326, 12213, 389, 1957, 287, 953, 282, 2272, 290, 326, 257, 1277, 2568, 44847, 7160, 13, 15075, 3481, 11, 816, 79, 2232, 1222, 277, 48038, 357, 22666, 257, 8, 11068, 262, 1176, 4466, 286, 24573, 12881, 287, 257, 35577, 18645, 7679, 290, 6515, 326, 12213, 287, 953, 282, 2272, 3051, 20736, 1022, 1333, 5643, 286, 12881, 3025, 2160, 286, 953, 282, 36525, 318, 4961, 284, 6632, 11, 2092, 284, 2568, 12213, 1022, 46287, 5277, 12881, 287, 3488, 32269, 47741, 13, 2158, 11, 15993, 2746, 1502, 7741, 7605, 357, 808, 1636, 1222, 288, 707, 1559, 2177, 8, 423, 407, 16083, 21514, 428, 3895, 13, 287, 1109, 11, 618, 953, 282, 26969, 1930, 1756, 884, 355, 24573, 389, 9322, 11, 42255, 12, 15236, 4981, 389, 3221, 6492, 11, 355, 262, 2368, 12, 2875, 763, 68, 202, 3456, 11192, 273, 318, 15715, 357, 72, 13, 304, 13, 749, 763, 68, 202, 35611, 389, 2566, 304, 1156, 422, 6632, 8, 329, 25783, 296, 32269, 12334, 82, 1231, 1948, 23606, 316, 1678, 13, 428, 16222, 364, 262, 10794, 286, 262, 10238, 11887, 286, 16252, 12213, 290, 5732, 31350, 3484, 11, 1201, 477, 1333, 23876, 12213, 423, 284, 307, 16726, 329, 19988, 262, 2746, 2651, 287, 640, 13, 262, 374, 301, 10156, 286, 428, 670, 318, 326, 356, 18077, 284, 4174, 1366, 12, 15808, 7605, 357, 2436, 388, 1222, 42392, 1636, 8309, 26, 45033, 1122, 2123, 435, 13, 1584, 26, 2376, 786, 559, 1222, 45033, 1122, 2864, 26, 45033, 1122, 2123, 435, 13, 13130, 8, 355, 257, 1724, 284, 5911, 5981, 1333, 23876, 12213, 287, 9426, 263, 5116, 4981, 286, 42291, 12334, 82, 13, 674, 4031, 318, 284, 7716, 5322, 1502, 4981, 31038, 257, 3094, 2837, 286, 16252, 981, 23934, 31350, 304, 202, 979, 1387, 290, 6179, 1799, 416, 778, 46493, 4939, 12213, 326, 389, 407, 5981, 329, 262, 17262, 13, 262, 39774, 286, 262, 5150, 3164, 318, 75, 16, 12, 16338, 1417, 20683, 357, 25520, 805, 2123, 435, 13, 3648, 26, 256, 571, 1477, 343, 3216, 2211, 828, 6768, 973, 287, 262, 13905, 2055, 284, 7925, 13544, 20473, 699, 10552, 286, 3716, 40522, 7268, 257, 24637, 286, 45718, 3033, 13, 262, 1729, 12, 10989, 304, 1156, 3379, 11, 1865, 24748, 87, 11, 3450, 286, 262, 75, 16, 16338, 5612, 3578, 25449, 262, 10375, 6356, 1917, 656, 257, 24748, 87, 6436, 5612, 1917, 326, 460, 307, 16019, 304, 202, 979, 1473, 11, 351, 257, 3748, 4610, 13, 1201, 645, 257, 3161, 72, 3725, 286, 262, 17262, 318, 7736, 1417, 11, 262, 3164, 318, 497, 12, 2164, 1328, 290, 5981, 12213, 389, 1852, 72, 1225, 287, 257, 4235, 12, 1525, 12, 14171, 6977, 1973, 262, 18911, 286, 12881, 13, 599, 45826, 12, 16963, 10720, 20683, 7605, 423, 587, 2904, 5150, 416, 45033, 1122, 290, 9949, 329, 7035, 513, 38945, 357, 1671, 403, 1122, 2123, 435, 13, 1584, 26, 38387, 5847, 2123, 435, 13, 2864, 8, 287, 262, 264, 521, 88, 9355, 357, 82, 29572, 1852, 72, 269, 341, 286, 1729, 29127, 17262, 828, 355, 257, 1724, 284, 7073, 13544, 20473, 699, 6382, 605, 24612, 286, 3341, 3025, 10238, 357, 4360, 7104, 8, 6954, 27490, 389, 29877, 287, 262, 2272, 286, 1744, 5499, 357, 1671, 403, 1122, 2123, 435, 13, 1584, 737, 674, 670, 1614, 32820, 422, 777, 304, 393, 912, 287, 262, 6650, 13, 618, 34391, 287, 13027, 2566, 304, 1156, 498, 1296, 11, 262, 6812, 959, 12, 301, 3369, 27490, 329, 13352, 601, 856, 12334, 82, 389, 5600, 2878, 20221, 29877, 11, 355, 691, 1178, 2846, 1391, 24748, 596, 11, 31116, 516, 2566, 514, 295, 290, 3833, 3386, 284, 45075, 2347, 1391, 8277, 284, 262, 4045, 29163, 13, 2158, 11, 618, 9426, 263, 5116, 4981, 389, 10944, 11, 884, 13204, 599, 45826, 318, 4143, 2626, 13, 644, 318, 17232, 318, 262, 599, 45826, 287, 262, 10375, 3912, 1022, 16252, 286, 6268, 326, 25457, 257, 34319, 72, 287, 42291, 1103, 38189, 13, 17640, 11, 356, 4031, 284, 14561, 428, 3895, 290, 1233, 359, 257, 2878, 20221, 29877, 2746, 326, 8186, 728, 262, 2656, 9172, 13, 287, 3090, 11, 599, 45826, 1852, 72, 269, 341, 5050, 423, 587, 5625, 11, 523, 1290, 11, 284, 5365, 1402, 9426, 263, 5116, 4981, 357, 5439, 786, 559, 1222, 45033, 1122, 2864, 828, 290, 340, 318, 407, 1865, 7247, 611, 777, 460, 307, 7736, 1417, 284, 5911, 290, 7925, 5981, 12213, 287, 4025, 4981, 287, 4381, 351, 262, 4920, 4286, 286, 2568, 12213, 287, 42291, 12334, 82, 13, 287, 428, 2565, 11, 674, 3164, 318, 5699, 284, 262, 2274, 670, 286, 299, 958, 1222, 256, 958, 64, 357, 4626, 828, 256, 958, 64, 2123, 435, 13, 357, 5304, 8, 290, 299, 958, 2123, 435, 13, 357, 7908, 737, 777, 7035, 9322, 3127, 12, 1169, 9997, 291, 599, 945, 72, 269, 341, 10581, 357, 3605, 805, 2864, 8, 284, 5911, 1994, 42726, 12, 1462, 12, 85, 26158, 12213, 287, 734, 12, 19577, 3488, 32269, 47741, 11, 16727, 29877, 4981, 326, 8006, 262, 6393, 11887, 286, 15014, 1329, 88, 334, 312, 12334, 351, 257, 5322, 1271, 286, 12213, 1022, 262, 976, 1588, 1271, 286, 2585, 13, 262, 1218, 10156, 286, 428, 3348, 318, 326, 356, 10716, 703, 599, 45826, 286, 2568, 12213, 8338, 319, 262, 850, 13200, 973, 284, 7716, 262, 9426, 263, 5116, 2746, 13, 4917, 281, 5035, 850, 13200, 329, 20128, 318, 20915, 355, 257, 9389, 4876, 357, 3919, 441, 2123, 435, 13, 1584, 828, 290, 1811, 953, 282]\n",
            "labels:\n",
            "'this draft was prepared using the latex style le belonging to the journal of fluid mechanics 1 l1-based sparsi cation of energy interactions in unsteady lid-driven cavity ow riccardo rubini1, davide lasagna1yand andrea da ronch1 1faculty of engineering and physical sciences, university of southampton, so17 1bj, southampton, united kingdom (received xx; revised xx; accepted xx) in this paper, sparsity-promoting regression techniques are employed to automati- cally identify from data relevant triadic interactions between modal structures in large galerkin-based models of two-dimensional unsteady ows. the approach produces in- terpretable, sparsely-connected models that reproduce the original dynamical behaviour at a much lower computational cost, as fewer triadic interactions need to be evaluated. the key feature of the approach is that dominant interactions are selected systematically from the solution of a convex optimisation problem, with a unique solution, and no a priori assumptions on the structure of scale interactions are required. we demonstrate this approach on models of two-dimensional lid-driven cavity ow at reynolds number re= 2\u0002104, where uid motion is chaotic. to understand the role of the subspace utilised for the galerkin projection on sparsity characteristics, we consider two families of models obtained from two di erent modal decomposition techniques. the rst uses energy-optimal proper orthogonal decomposition modes, while the second uses modes oscillating at a single frequency obtained from discrete fourier transform of the ow snapshots. we show that, in both cases, and despite no a-priori physical knowledge is incorporated into the approach, relevant interactions across the hierarchy of modes are identi ed in agreement with the expected picture of scale interactions in two- dimensional turbulence. yet, substantial structural changes in the interaction pattern and a quantitatively di erent sparsity are observed. finally, although not directly enforced in the procedure, the sparsi ed models have excellent long-term stability properties and correctly reproduce the spatio-temporal evolution of dominant ow structures in the cavity. 1. introduction in the classical description of developed turbulent ows (lumley 1979; pope 2001; jim\u0013 enez 2018), energy is transferred across the hierarchy of coherent structures via nonlinear triadic interactions. implicit in this picture is the fact that not all interactions have the same importance, but they occur in preferential patterns. in fact, extensive numerical evidence suggests that the nonlinear interaction pattern among coherent structures is sparse. the evolution of structures at a certain length scale depends predominantly upon a subset of all other structures (kraichnan 1971; ohkitani 1990; brasseur & wei 1994) and the in uence of interactions with the complementary set of structures can be generally neglected with minor global e ects. successful attempts to construct a reduced set of equations that exploit this sparsity have been made in the past, often for canonical geometries where triadic interactions are conveniently examined in fourier space and using a coarse-grained partitioning of yemail address for correspondence: davide. lasagna@soton. ac. ukarxiv:2006. 05736v2 [physics. flu-dyn] 23 jul 2020 2 r. rubini, d. lasagna and a. da ronch the hierarchy of scales. laval et al. (1999) considered two-dimensional homogeneous decaying turbulence and developed a reduced set of coupled partial di erential equations governing the evolution of the large and small scales. in this model, only dominant terms were retained based on observations from direct numerical simulation. with the goal of identifying fundamental mechanisms underlying wall turbulence, thomas et al. (2015) developed nonlinear reduced models of plane couette ow directly from the governing equations by rst partitioning the ow into a streamwise-averaged mean and a pertur- bation eld, and then neglecting nonlinear interactions among the streamwise varying perturbations, i. e. the perturbation-perturbation nonlinearity (thomas et al. 2014). the models captured well-established roll-streak dynamical features of wall turbulence and its statistics in a computationally e\u000ecient framework. the models also sustained turbulent dynamics down to minimal con gurations where interactions between the streamwise mean ow and only one single streamwise wavenumber are retained. when reduced-order dynamical representations are derived using galerkin projection on a low-dimensional subspace identi ed by a set of modal structures (fletcher 1984; rowley & dawson 2017), triadic interactions are conveniently studied in modal space by examining a third-order coe\u000ecient tensor arising from projection of the basis function on the convective term of the navier-stokes equations (noack et al. 2008, 2011). sparsity characteristics have also been observed in this reduced-order setting. couplet et al. (2003) constructed galerkin models of the separated turbulent ow past a backward-facing step using proper orthogonal decomposition (pod) modes (lumley 1970; sirovich 1987) and observed that the energy transfer pattern in modal space shares many properties with its counterpart in isotropic homogeneous three-dimensional turbulent ows (yeung et al. 1995). for instance, the authors observed that interactions are local in modal space and that a direct energy cascade exists. analogously, rempfer & fasel (1994 a) examined the power budget of pod modes in a transitional boundary layer and observed that interactions in modal space occur predominantly between triads of modes whose sum of modal indices is equal to zero, similar to energy interactions between fourier modes in homogeneous turbulence. however, classical model order reduction techniques (rowley & dawson 2017) have not traditionally exploited this feature. in fact, when modal decompositions such as pod are employed, densely-connected models are usually obtained, as the third-order coe\u000ecient tensor is dense (i. e. most coe\u000ecients are di erent from zero) for inhomogeneous ows without particular symmetries. this hinders the interpretation of the underlying physics of scales interactions and increases computational costs, since all triadic interactions have to be evaluated for advancing the model forward in time. the rst contribution of this work is that we propose to apply data-driven techniques (blum & langley 1997; brunton et al. 2016; loiseau & brunton 2018; brunton et al. 2019) as a means to identify relevant triadic interactions in galerkin models of turbulent ows. our aim is to generate reduced order models resolving a wide range of scales while preserving computational e\u000eciency and interpretability by pruning weak interactions that are not relevant for the dynamics. the cornerstone of the proposed approach isl1-regularised regression (friedman et al. 2008; tibshirani 2013), widely used in the statistical community to extract parsimonious representation of complex datasets containing a subset of predominant features. the non-di erentiable, yet convex, nature of thel1regularisation allows transforming the interaction selection problem into a convex optimisation problem that can be solved e\u000eciently, with a unique solution. since no a priori knowledge of the dynamics is utilised, the approach is ne-grained and relevant interactions are identi ed in a mode-by-mode fashion across the hierarchy of modes. sparsity-promoting regression techniques have been recently proposed by brunton and guidelines for authors 3 coworkers (brunton et al. 2016; kaiser et al. 2018) in the sindy framework (sparse identi cation of nonlinear dynamics), as a means to discover parsimonious dynamical representations of systems whose underlying (but hidden) evolution equations are sparse in the space of possible functions (brunton et al. 2016). our work deviates from these e orts in the perspective. when formulated in partial di erential form, the navier-stokes equations for incompressible ows are indeed structurally sparse, as only few terms { convection, viscous di usion and pressure forces to conserve mass { participate to the overall equilibrium. however, when galerkin models are derived, such structural sparsity is generally lost. what is preserved is the sparsity in the interaction pattern between scales of motion that emerges a posteriori in turbulent realisations. fundamentally, we aim to exploit this feature and distill a structurally sparse model that reproduces the original behaviour. in addition, sparsity identi cation methods have been applied, so far, to relatively small galerkin models (loiseau & brunton 2018), and it is not yet understood if these can be utilised to identify and extract relevant interactions in larger models in agreement with the established picture of energy interactions in turbulent ows. in this sense, our approach is closer to the recent work of nair & taira (2015), taira et al. (2016) and nair et al. (2018). these authors employed network-theoretic sparsi cation approaches (newman 2018) to identify key vortex-to-vortex interactions in two-dimensional homogeneous turbulence, obtaining sparse models that capture the essential physics of unsteady uid ow with a reduced number of interactions between the same large number of states. the second contribution of this paper is that we examine how sparsity of energy interactions depends on the subspace used to generate the galerkin model. finding an appropriate subspace for projection is recognised as a challenging task (noack et al. 2016), and several modal\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:08:02,555 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:08:02,556 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "model.safetensors: 100% 2.84G/2.84G [00:14<00:00, 199MB/s]\n",
            "[INFO|modeling_utils.py:3982] 2025-04-25 20:08:17,142 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/model.safetensors\n",
            "[INFO|modeling_utils.py:1633] 2025-04-25 20:08:17,272 >> Instantiating PhiForCausalLM model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:1140] 2025-04-25 20:08:17,280 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|modeling_utils.py:4970] 2025-04-25 20:08:18,683 >> All model checkpoint weights were used when initializing PhiForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4978] 2025-04-25 20:08:18,683 >> All the weights of PhiForCausalLM were initialized from the model checkpoint at microsoft/phi-1_5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PhiForCausalLM for predictions without further training.\n",
            "generation_config.json: 100% 74.0/74.0 [00:00<00:00, 641kB/s]\n",
            "[INFO|configuration_utils.py:1095] 2025-04-25 20:08:18,953 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/generation_config.json\n",
            "[INFO|configuration_utils.py:1140] 2025-04-25 20:08:18,953 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|2025-04-25 20:08:18] llamafactory.model.model_utils.checkpointing:157 >> Gradient checkpointing enabled.\n",
            "[INFO|2025-04-25 20:08:18] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-04-25 20:08:18] llamafactory.model.adapter:157 >> Upcasting trainable params to float32.\n",
            "[INFO|2025-04-25 20:08:18] llamafactory.model.adapter:157 >> Fine-tuning method: LoRA\n",
            "[INFO|2025-04-25 20:08:18] llamafactory.model.model_utils.misc:157 >> Found linear modules: v_proj,k_proj,q_proj,dense,fc2,fc1\n",
            "[INFO|2025-04-25 20:08:20] llamafactory.model.loader:157 >> trainable params: 7,077,888 || all params: 1,425,348,608 || trainable%: 0.4966\n",
            "[INFO|trainer.py:746] 2025-04-25 20:08:20,072 >> Using auto half precision backend\n",
            "[WARNING|trainer.py:781] 2025-04-25 20:08:20,073 >> No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "[INFO|trainer.py:2405] 2025-04-25 20:08:20,488 >> ***** Running training *****\n",
            "[INFO|trainer.py:2406] 2025-04-25 20:08:20,488 >>   Num examples = 18\n",
            "[INFO|trainer.py:2407] 2025-04-25 20:08:20,488 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2408] 2025-04-25 20:08:20,489 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:2411] 2025-04-25 20:08:20,489 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2412] 2025-04-25 20:08:20,489 >>   Gradient Accumulation steps = 8\n",
            "[INFO|trainer.py:2413] 2025-04-25 20:08:20,489 >>   Total optimization steps = 3\n",
            "[INFO|trainer.py:2414] 2025-04-25 20:08:20,492 >>   Number of trainable parameters = 7,077,888\n",
            "100% 3/3 [01:03<00:00, 21.64s/it][INFO|trainer.py:3942] 2025-04-25 20:09:24,474 >> Saving model checkpoint to saves/Phi-1.5-1.3B/lora/train_2025-04-25-20-05-37/checkpoint-3\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:09:24,682 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:09:24,683 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2500] 2025-04-25 20:09:24,763 >> tokenizer config file saved in saves/Phi-1.5-1.3B/lora/train_2025-04-25-20-05-37/checkpoint-3/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2509] 2025-04-25 20:09:24,764 >> Special tokens file saved in saves/Phi-1.5-1.3B/lora/train_2025-04-25-20-05-37/checkpoint-3/special_tokens_map.json\n",
            "[INFO|trainer.py:2657] 2025-04-25 20:09:24,989 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 64.4967, 'train_samples_per_second': 0.837, 'train_steps_per_second': 0.047, 'train_loss': 3.282660802205404, 'epoch': 1.89, 'num_input_tokens_seen': 69632}\n",
            "100% 3/3 [01:04<00:00, 21.50s/it]\n",
            "[INFO|trainer.py:3942] 2025-04-25 20:09:24,991 >> Saving model checkpoint to saves/Phi-1.5-1.3B/lora/train_2025-04-25-20-05-37\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:09:25,641 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:09:25,642 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2500] 2025-04-25 20:09:25,806 >> tokenizer config file saved in saves/Phi-1.5-1.3B/lora/train_2025-04-25-20-05-37/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2509] 2025-04-25 20:09:25,809 >> Special tokens file saved in saves/Phi-1.5-1.3B/lora/train_2025-04-25-20-05-37/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =     1.8889\n",
            "  num_input_tokens_seen    =      69632\n",
            "  total_flos               =   513801GF\n",
            "  train_loss               =     3.2827\n",
            "  train_runtime            = 0:01:04.49\n",
            "  train_samples_per_second =      0.837\n",
            "  train_steps_per_second   =      0.047\n",
            "[WARNING|2025-04-25 20:09:25] llamafactory.extras.ploting:162 >> No metric loss to plot.\n",
            "[WARNING|2025-04-25 20:09:25] llamafactory.extras.ploting:162 >> No metric eval_loss to plot.\n",
            "[WARNING|2025-04-25 20:09:25] llamafactory.extras.ploting:162 >> No metric eval_accuracy to plot.\n",
            "[INFO|modelcard.py:449] 2025-04-25 20:09:25,976 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "2025-04-25 20:11:18.551279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745611878.571840    4852 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745611878.578201    4852 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 563, in from_name\n",
            "    return next(cls.discover(name=name))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "StopIteration\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/versions.py\", line 102, in require_version\n",
            "    got_ver = importlib.metadata.version(pkg)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 1009, in version\n",
            "    return distribution(distribution_name).version\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 982, in distribution\n",
            "    return Distribution.from_name(distribution_name)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 565, in from_name\n",
            "    raise PackageNotFoundError(name)\n",
            "importlib.metadata.PackageNotFoundError: No package metadata was found for rouge_chinese\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llamafactory/cli.py\", line 118, in main\n",
            "    run_exp()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llamafactory/train/tuner.py\", line 103, in run_exp\n",
            "    _training_function(config={\"args\": args, \"callbacks\": callbacks})\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llamafactory/train/tuner.py\", line 54, in _training_function\n",
            "    model_args, data_args, training_args, finetuning_args, generating_args = get_train_args(args)\n",
            "                                                                             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llamafactory/hparams/parser.py\", line 292, in get_train_args\n",
            "    _check_extra_dependencies(model_args, finetuning_args, training_args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llamafactory/hparams/parser.py\", line 161, in _check_extra_dependencies\n",
            "    check_version(\"rouge_chinese\", mandatory=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/llamafactory/extras/misc.py\", line 90, in check_version\n",
            "    require_version(requirement, hint)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/versions.py\", line 104, in require_version\n",
            "    raise importlib.metadata.PackageNotFoundError(\n",
            "importlib.metadata.PackageNotFoundError: No package metadata was found for The 'rouge_chinese' distribution was not found and is required by this application. \n",
            "To fix: run `pip install rouge_chinese`.\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:12:01,620 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:12:01,623 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:01,720 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:01,720 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:01,720 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:01,720 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:01,720 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:01,720 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:01,720 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:12:02,252 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:12:02,253 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:02,343 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:02,343 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:02,343 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:02,343 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:02,343 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:02,343 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:02,344 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|2025-04-25 20:12:02] llamafactory.data.template:157 >> Add pad token: <|endoftext|>\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:12:02,586 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:12:02,586 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|2025-04-25 20:12:02] llamafactory.model.patcher:157 >> Using KV cache for faster generation.\n",
            "[INFO|modeling_utils.py:3982] 2025-04-25 20:12:02,786 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/model.safetensors\n",
            "[INFO|modeling_utils.py:1633] 2025-04-25 20:12:02,801 >> Instantiating PhiForCausalLM model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:1140] 2025-04-25 20:12:02,803 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|modeling_utils.py:4970] 2025-04-25 20:12:04,325 >> All model checkpoint weights were used when initializing PhiForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4978] 2025-04-25 20:12:04,325 >> All the weights of PhiForCausalLM were initialized from the model checkpoint at microsoft/phi-1_5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PhiForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1095] 2025-04-25 20:12:04,606 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/generation_config.json\n",
            "[INFO|configuration_utils.py:1140] 2025-04-25 20:12:04,607 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|2025-04-25 20:12:04] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-04-25 20:12:04] llamafactory.model.loader:157 >> all params: 1,418,270,720\n",
            "[WARNING|2025-04-25 20:12:04] llamafactory.chat.hf_engine:168 >> There is no current event loop, creating a new one.\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:12:55,605 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:12:55,606 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:55,697 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:55,697 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:55,697 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:55,697 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:55,697 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:55,698 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:55,698 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:12:56,210 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:12:56,211 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:56,300 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:56,300 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:56,300 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:56,300 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:56,300 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:56,301 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2050] 2025-04-25 20:12:56,301 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|2025-04-25 20:12:56] llamafactory.data.template:157 >> Add pad token: <|endoftext|>\n",
            "[INFO|configuration_utils.py:699] 2025-04-25 20:12:56,542 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n",
            "[INFO|configuration_utils.py:771] 2025-04-25 20:12:56,543 >> Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-1_5\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": null,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": null,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.5,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.0,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "[INFO|2025-04-25 20:12:56] llamafactory.model.patcher:157 >> Using KV cache for faster generation.\n",
            "[INFO|modeling_utils.py:3982] 2025-04-25 20:12:56,544 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/model.safetensors\n",
            "[INFO|modeling_utils.py:1633] 2025-04-25 20:12:56,557 >> Instantiating PhiForCausalLM model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:1140] 2025-04-25 20:12:56,559 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|modeling_utils.py:4970] 2025-04-25 20:12:58,149 >> All model checkpoint weights were used when initializing PhiForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4978] 2025-04-25 20:12:58,149 >> All the weights of PhiForCausalLM were initialized from the model checkpoint at microsoft/phi-1_5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PhiForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1095] 2025-04-25 20:12:58,374 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/generation_config.json\n",
            "[INFO|configuration_utils.py:1140] 2025-04-25 20:12:58,374 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|2025-04-25 20:12:58] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-04-25 20:12:59] llamafactory.model.adapter:157 >> Merged 1 adapter(s).\n",
            "[INFO|2025-04-25 20:12:59] llamafactory.model.adapter:157 >> Loaded adapter(s): saves/Phi-1.5-1.3B/lora/train_2025-04-25-20-05-37\n",
            "[INFO|2025-04-25 20:12:59] llamafactory.model.loader:157 >> all params: 1,418,270,720\n",
            "[WARNING|logging.py:329] 2025-04-25 20:15:26,571 >> This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
          ]
        }
      ]
    }
  ]
}